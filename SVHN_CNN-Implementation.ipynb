{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "# Machine Learning Nanodegree Capstone\n",
    "\n",
    "This notebook implements the Convolutional Neural Network for doing the housenumber classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup filename for saving data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial_version = 'cnn-ver-3'\n",
    "\n",
    "logdirectory = \"./logs/\"+trial_version+\"/\"\n",
    "if not os.path.exists(logdirectory):\n",
    "    os.makedirs(logdirectory)\n",
    "    \n",
    "logging.basicConfig(\n",
    "    filename=logdirectory+'data_export_'+trial_version+'.csv', filemode='w',\n",
    "    level=logging.DEBUG, \n",
    "    format='%(asctime)s,%(step)s,%(minibatch_loss)s,%(minibatch_accuracy)s,'+\\\n",
    "            '%(validation_accuracy)s,%(test_accuracy)s',\n",
    "    datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "# File mames for saving and restoring the model\n",
    "saver_filename= logdirectory+\"model_\"+trial_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm the Tensorflow and Python version that we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the dataset from the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = 'SVHN_real.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function for plotting images\n",
    "Function used to plot 9 images in a 3x3 grid, and writing the true and predicted classes below each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is adapted from: \n",
    "# https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/03_PrettyTensor.ipynb\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing if we need to print ensemble and best-net.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Interpolation type.\n",
    "        if smooth:\n",
    "            interpolation = 'spline16'\n",
    "        else:\n",
    "            interpolation = 'nearest'\n",
    "\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i, :, :, :],\n",
    "                  interpolation=interpolation)\n",
    "            \n",
    "        # Name of the true class.\n",
    "        cls_true_name = cls_true[i]\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true_name)\n",
    "        else:\n",
    "            # Name of the predicted class.\n",
    "            cls_pred_name = cls_pred[i]\n",
    "\n",
    "            xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting some example images\n",
    "\n",
    "Here are 9 images from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = test_dataset[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = test_labels[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true, smooth=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "### Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for getting the nth digit from an integer\n",
    "# For example nth_digit(2534,2) = 5\n",
    "\n",
    "def nth_digit(number,n):\n",
    "    l = len(str(number))\n",
    "    if l >= n:\n",
    "        return int(str(number)[n-1])\n",
    "    else:\n",
    "        return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [],
   "source": [
    "image_size = 54\n",
    "num_labels = 11\n",
    "num_channels = 3\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "\n",
    "  # get the number of digits in the house number, e.g. 218 has labels_num_length=3\n",
    "  labels_num_length = np.asarray(map(lambda x:len(str(x)), labels))\n",
    "  \n",
    "  # get the individual digits from the house number, 10 mean blank\n",
    "  # For example label digits for the number 218 are: [2,1,8,10,10] \n",
    "  labels_digit1 = np.asarray(map(lambda x:nth_digit(x,1), labels))\n",
    "  labels_digit2 = np.asarray(map(lambda x:nth_digit(x,2), labels))\n",
    "  labels_digit3 = np.asarray(map(lambda x:nth_digit(x,3), labels))\n",
    "  labels_digit4 = np.asarray(map(lambda x:nth_digit(x,4), labels))\n",
    "  labels_digit5 = np.asarray(map(lambda x:nth_digit(x,5), labels))\n",
    "\n",
    "  # Turn the labels above into 1-hot encodings\n",
    "  labels_num_length = (np.arange(num_labels) == labels_num_length[:,None]).astype(np.int32)\n",
    "  labels_digit1 = (np.arange(num_labels) == labels_digit1[:,None]).astype(np.int32)\n",
    "  labels_digit2 = (np.arange(num_labels) == labels_digit2[:,None]).astype(np.int32)\n",
    "  labels_digit3 = (np.arange(num_labels) == labels_digit3[:,None]).astype(np.int32)\n",
    "  labels_digit4 = (np.arange(num_labels) == labels_digit4[:,None]).astype(np.int32)\n",
    "  labels_digit5 = (np.arange(num_labels) == labels_digit5[:,None]).astype(np.int32)\n",
    "\n",
    "  # Combine the individual 1-hot encodings into a single matrix\n",
    "  labels_list = np.stack(\n",
    "        (labels_num_length, labels_digit1, labels_digit2, \n",
    "         labels_digit3, labels_digit4, labels_digit5), axis=1)\n",
    "  return dataset, labels_list\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(test_labels[8]) # compare with the last example image above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ohe_to_housenumbers(ohe_labels):\n",
    "    lengths = ohe_labels[:,0,:]\n",
    "    digits1 = ohe_labels[:,1,:]\n",
    "    digits2 = ohe_labels[:,2,:]\n",
    "    digits3 = ohe_labels[:,3,:]\n",
    "    digits4 = ohe_labels[:,4,:]\n",
    "    digits5 = ohe_labels[:,5,:]\n",
    "    \n",
    "    num_labels = len(ohe_labels)\n",
    "    housenumbers = np.zeros(shape=num_labels, dtype=np.int)\n",
    "    \n",
    "    for i in range(num_labels):\n",
    "        l = np.argmax(lengths[i])\n",
    "        d1 = np.argmax(digits1[i])\n",
    "        d2 = np.argmax(digits2[i])\n",
    "        d3 = np.argmax(digits3[i])\n",
    "        d4 = np.argmax(digits4[i])\n",
    "        d5 = np.argmax(digits5[i])\n",
    "        d = str(d1)+str(d2)+str(d3)+str(d4)+str(d5)\n",
    "        housenumbers[i] = int(d[:min(l,5)])\n",
    "        \n",
    "    return housenumbers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ohe_to_housenumbers(test_labels[:9])) # compare with example images above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_labels = 11 # digits 0-9 and 10 for blank\n",
    "num_logits = 6 # 5 digits plus number length\n",
    "num_channels = 3 # RGB color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, num_channels], name='x')\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_logits,num_labels], name='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main_network(images, training):\n",
    "    # Wrap the input images as a Pretty Tensor object.\n",
    "    x_pretty = pt.wrap(images)\n",
    "\n",
    "    # Pretty Tensor uses special numbers to distinguish between\n",
    "    # the training and testing phases.\n",
    "    if training:\n",
    "        phase = pt.Phase.train\n",
    "    else:\n",
    "        phase = pt.Phase.infer\n",
    "\n",
    "    # Create the convolutional neural network using Pretty Tensor.\n",
    "    with pt.defaults_scope(activation_fn=tf.nn.relu, phase=phase):\n",
    "        network_base = x_pretty.\\\n",
    "            apply(tf.image.rgb_to_grayscale).\\\n",
    "            conv2d(kernel=5, depth=48, name='layer_conv1', batch_normalize=True).\\\n",
    "            max_pool(kernel=2, stride=2).\\\n",
    "            conv2d(kernel=5, depth=64, name='layer_conv2', batch_normalize=True).\\\n",
    "            max_pool(kernel=2, stride=2).\\\n",
    "            conv2d(kernel=5, depth=128, name='layer_conv3', batch_normalize=True).\\\n",
    "            max_pool(kernel=2, stride=2).\\\n",
    "            conv2d(kernel=5, depth=160, name='layer_conv4', batch_normalize=True).\\\n",
    "            max_pool(kernel=2, stride=2).\\\n",
    "            dropout(0.95).\\\n",
    "            flatten().\\\n",
    "            fully_connected(size=2048, name='layer_fc1').\\\n",
    "            dropout(0.95).\\\n",
    "            fully_connected(size=1024, name='layer_fc2')\n",
    "        y_pred1, loss1 = network_base.softmax_classifier(class_count=num_labels, \n",
    "                                                         labels=y_true[:,0,:])\n",
    "        y_pred2, loss2 = network_base.softmax_classifier(class_count=num_labels, \n",
    "                                                         labels=y_true[:,1,:])\n",
    "        y_pred3, loss3 = network_base.softmax_classifier(class_count=num_labels, \n",
    "                                                         labels=y_true[:,2,:])\n",
    "        y_pred4, loss4 = network_base.softmax_classifier(class_count=num_labels, \n",
    "                                                         labels=y_true[:,3,:])\n",
    "        y_pred5, loss5 = network_base.softmax_classifier(class_count=num_labels, \n",
    "                                                         labels=y_true[:,4,:])\n",
    "        y_pred6, loss6 = network_base.softmax_classifier(class_count=num_labels, \n",
    "                                                         labels=y_true[:,5,:])\n",
    "        loss = pt.create_composite_loss([loss1,loss2,loss3,loss4,loss5,loss6])\n",
    "        y_pred = tf.pack([y_pred1,y_pred2,y_pred3,y_pred4,y_pred5,y_pred6],axis=1)\n",
    "        \n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_network(training):\n",
    "    # Wrap the neural network in the scope named 'network'.\n",
    "    # Create new variables during training, and re-use during testing.\n",
    "    with tf.variable_scope('network', reuse=not training):\n",
    "        # Just rename the input placeholder variable for convenience.\n",
    "        images = x\n",
    "\n",
    "        # Create TensorFlow graph for the main processing.\n",
    "        y_pred, loss = main_network(images=images, training=training)\n",
    "\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(initial_value=0,\n",
    "                          name='global_step', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, loss = create_network(training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred, _ = create_network(training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Trying to restore last checkpoint ...\")\n",
    "\n",
    "    # Use TensorFlow to find the latest checkpoint - if any.\n",
    "    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=logdirectory)\n",
    "\n",
    "    # Try and load the data in the checkpoint.\n",
    "    saver.restore(session, save_path=last_chk_path)\n",
    "\n",
    "    # If we get to this point, the checkpoint was successfully loaded.\n",
    "    print(\"Restored checkpoint from:\", last_chk_path)\n",
    "except:\n",
    "    # If the above failed for some reason, simply\n",
    "    # initialize all the variables for the TensorFlow graph.\n",
    "    print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "    session.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch():\n",
    "    # Number of images in the training-set.\n",
    "    num_images = len(train_dataset)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=train_batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random images and labels.\n",
    "    x_batch = train_dataset[idx, :, :, :]\n",
    "    y_batch = train_labels[idx, :]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred, correct):\n",
    "    # This function is called from print_test_accuracy() below.\n",
    "\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # correct is a boolean array whether the predicted class\n",
    "    # is equal to the true class for each image in the test-set.\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = test_dataset[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = ohe_to_housenumbers(test_labels[incorrect])\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data-set in batches of this size to limit RAM usage.\n",
    "batch_size = 256\n",
    "\n",
    "def predict_cls(images, labels, cls_true):\n",
    "    # Number of images.\n",
    "    num_images = len(images)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_images, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_images:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + batch_size, num_images)\n",
    "\n",
    "        # Create a feed-dict with the images and labels\n",
    "        # between index i and j.\n",
    "        feed_dict = {x: images[i:j, :],\n",
    "                     y_true: labels[i:j, :]}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = ohe_to_housenumbers(session.run(y_pred, feed_dict=feed_dict))\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "    return correct, cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_cls_test():\n",
    "    return predict_cls(images = test_dataset,\n",
    "                       labels = test_labels,\n",
    "                       cls_true = ohe_to_housenumbers(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_accuracy(correct):\n",
    "    # When averaging a boolean array, False means 0 and True means 1.\n",
    "    # So we are calculating: number of True / len(correct) which is\n",
    "    # the same as the classification accuracy.\n",
    "    \n",
    "    # Return the classification accuracy\n",
    "    # and the number of correct classifications.\n",
    "    return correct.mean(), correct.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Best validation accuracy seen so far.\n",
    "    best_validation_accuracy = 0.0\n",
    "\n",
    "    # Iteration-number for last improvement to validation accuracy.\n",
    "    last_improvement = 0\n",
    "\n",
    "    # Stop optimization if no improvement found in this many iterations.\n",
    "    require_improvement = 1000\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = random_batch()\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        # We also want to retrieve the global_step counter.\n",
    "        batch_loss, i_global, _ = session.run([loss, global_step, optimizer],\n",
    "                                  feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status to screen at regular intervals (and last).\n",
    "        if (i_global % 10 == 0) or (i == num_iterations - 1):            \n",
    "            print('Minibatch loss at step %d: %f' % (i_global, batch_loss))\n",
    "    \n",
    "            # Get accuracy on the Mini-batch set\n",
    "            correct, cls_pred = predict_cls(images = x_batch,\n",
    "                                            labels = y_true_batch,\n",
    "                                          cls_true = ohe_to_housenumbers(y_true_batch))\n",
    "            # Classification accuracy and the number of correct classifications.\n",
    "            mb_acc, num_correct = classification_accuracy(correct)\n",
    "            # Number of images being classified.\n",
    "            num_images = len(correct)\n",
    "            # Print the accuracy.\n",
    "            msg = \"Accuracy on Mini-batch: {0:.1%} ({1} / {2})\"\n",
    "            print(msg.format(mb_acc, num_correct, num_images))\n",
    "            d = {'step': i_global, 'minibatch_loss': batch_loss, 'minibatch_accuracy': mb_acc,\n",
    "             'validation_accuracy': '-', 'test_accuracy': '-'}\n",
    "            logging.info('logging progress...', extra=d)\n",
    "\n",
    "        # Save a checkpoint to disk every 100 iterations (and last).\n",
    "        if (i_global % 100 == 0) or (i == num_iterations - 1):\n",
    "            \n",
    "            # Get accuracy on the validation set\n",
    "            correct, cls_pred = predict_cls(images = valid_dataset,\n",
    "                                            labels = valid_labels,\n",
    "                                          cls_true = ohe_to_housenumbers(valid_labels))\n",
    "            # Classification accuracy and the number of correct classifications.\n",
    "            val_acc, num_correct = classification_accuracy(correct)\n",
    "            # Number of images being classified.\n",
    "            num_images = len(correct)\n",
    "            # Print the accuracy.\n",
    "            d = {'step': i_global, 'minibatch_loss': '-', 'minibatch_accuracy': '-',\n",
    "             'validation_accuracy': val_acc, 'test_accuracy': '-'}\n",
    "            logging.info('logging progress...', extra=d)\n",
    "            \n",
    "            \n",
    "            # If validation accuracy is an improvement over best-known.\n",
    "            if val_acc > best_validation_accuracy:\n",
    "                # Update the best-known validation accuracy.\n",
    "                best_validation_accuracy = val_acc\n",
    "                \n",
    "                # Set the iteration for the last improvement to current.\n",
    "                last_improvement = i_global\n",
    "\n",
    "                # Save all variables of the TensorFlow graph to file.\n",
    "                saver.save(sess=session, save_path=saver_filename,\n",
    "                       global_step=global_step)\n",
    "                print(\"Saved checkpoint.\")\n",
    "\n",
    "                # A string to be printed below, shows improvement found.\n",
    "                improved_str = '*'\n",
    "            else:\n",
    "                # An empty string to be printed below.\n",
    "                # Shows that no improvement was found.\n",
    "                improved_str = ''\n",
    "            \n",
    "            msg = \"Accuracy on Validation Set: {0:.1%} ({1} / {2}) {3}\"\n",
    "            print(msg.format(val_acc, num_correct, num_images, improved_str))\n",
    "\n",
    "        # If no improvement found in the required number of iterations.\n",
    "        if i_global - last_improvement > require_improvement:\n",
    "            print(\"No improvement found in a while, stopping optimization.\")\n",
    "            # Break out from the for-loop.\n",
    "            break\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_test_accuracy(show_example_errors=False):   \n",
    "    # For all the images in the test-set,\n",
    "    # calculate the predicted classes and whether they are correct.\n",
    "    correct, cls_pred = predict_cls_test()\n",
    "    \n",
    "    # Classification accuracy and the number of correct classifications.\n",
    "    acc, num_correct = classification_accuracy(correct)\n",
    "    \n",
    "    # Number of images being classified.\n",
    "    num_images = len(correct)\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, num_correct, num_images))\n",
    "    \n",
    "    d = {'step': '-', 'minibatch_loss': '-', 'minibatch_accuracy': '-',\n",
    "         'validation_accuracy': '-', 'test_accuracy': acc}\n",
    "    logging.info('logging progress...', extra=d)\n",
    "\n",
    "    # Plot some examples of mis-classifications, if desired.\n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    optimize(num_iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_test_accuracy(show_example_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
